CC 分词器
==================================

CC分词器简单地使用给定的词典进行分词。CC的底层依赖 `StandardTokenizer` ，故而可以很好滴对多种语言进行切分，而不仅仅是中文。
CC的词典是基于序列匹配的，故而可以支持中英文混排等情况。


定位和限制
----------------------------------

CC分词器提供简单直观的切分方法，不提供各种高级特性。

在评价检索效果时，一般主要考虑召回率和精确率。 Paoding、IK等业界知名分词器可能提供了更高级的特性，如中文数字识别、歧义识别等特性。
而CC暂不考虑这些，因为目前暂没有很好滴歧义算法，且很难评价好坏。而有时我们希望尽量返回更多的内容，甚至于类似SQL的“LIKE”操作，
然后交由人工识别。CC目前主要考虑的就是这种场景，故而只要文档中存在词典中制定的序列，则就认为是一个词。


原理
----------------------------------

首先使用 `StandardTokenizer` 对用户输入进行切分，然后使用Token序列匹配的方式对词典中的内容进行匹配。
匹配的方式类似于Lucene提供的 `synonym` 方式。

Maven使用方法
----------------------------------

```
<dependency>
    <groupId>com.thihy</groupId>
    <artifactId>cc-analysis</artifactId>
    <version>0.1.0</version>
</dependency>
```
